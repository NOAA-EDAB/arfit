[{"path":"https://andybeet.github.io/arfit/articles/Equations.html","id":"eq-1","dir":"Articles","previous_headings":"","what":"Eq 1","title":"Equations","text":"Yt=β0+β1t+ϵt\\begin{align} \\tag{1}   Y_t = \\beta_0 + \\beta_1 t + \\epsilon_t   \\end{align}","code":""},{"path":"https://andybeet.github.io/arfit/articles/Equations.html","id":"eq-2","dir":"Articles","previous_headings":"","what":"Eq 2","title":"Equations","text":"L(θ_;y_)=∏t=2np(Yt=yt|Yt−1=yt−1)p(Y1=y1)\\begin{align} \\tag{2} \\mathrm{L}\\left( \\underline{\\theta}; \\underline{y} \\right )= \\prod^n_{t=2} p\\left(Y_t = y_t | Y_{t-1}=y_{t-1}\\right)  p\\left(Y_1=y_1 \\right)  \\end{align}","code":""},{"path":"https://andybeet.github.io/arfit/articles/Equations.html","id":"eq-3","dir":"Articles","previous_headings":"","what":"Eq 3","title":"Equations","text":"logL(θ_;y_)=−n2log2π−nlogσ+12log(1−ϕ2)−12σ2((1−ϕ2)(y1−β0−β1)2+∑t=2n(yt−ϕyt−1−β0(1−ϕ2)−tβ1+ϕ(t−1)β1)2)\\begin{align} \\tag{3} logL\\left( \\underline{\\theta}; \\underline{y} \\right ) = & -\\frac{n}{2}log2\\pi - nlog\\sigma + \\frac{1}{2}log(1-\\phi^2) \\\\ &-\\frac{1}{2\\sigma^2}\\left( (1-\\phi^2)(y_1-\\beta_0-\\beta_1)^2 + \\sum^n_{t=2}(y_t - \\phi y_{t-1}-\\beta_0(1-\\phi^2) -t\\beta_1 + \\phi(t-1)\\beta_1)^2 \\right)   \\end{align}","code":""},{"path":"https://andybeet.github.io/arfit/articles/Equations.html","id":"eq-4","dir":"Articles","previous_headings":"","what":"Eq 4","title":"Equations","text":"σ̂2=1n((1−ϕ2)(y1−β0−β1)2+∑t=2n(yt−ϕyt−1−β0(1−ϕ2)−tβ1+ϕ(t−1)β1)2)\\begin{align} \\tag{4} \\hat\\sigma^2 = \\frac{1}{n}\\left( (1-\\phi^2)(y_1-\\beta_0-\\beta_1)^2 + \\sum^n_{t=2}(y_t - \\phi y_{t-1}-\\beta_0(1-\\phi^2) - t\\beta_1 + \\phi(t-1)\\beta_1)^2 \\right)  \\end{align}","code":""},{"path":"https://andybeet.github.io/arfit/articles/Equations.html","id":"eq-5","dir":"Articles","previous_headings":"","what":"Eq 5","title":"Equations","text":"logL(β_,ϕ;y_)=const.+12log(1−ϕ2)−n2log((1−ϕ2)(y1−β0−β1)2+∑t=2n(yt−ϕyt−1−β0(1−ϕ2)−tβ1+ϕ(t−1)β1)2)=const.+12log(1−ϕ2)−n2log((1−ϕ2)(y1−X1β_)2+∑t=2n(yt−ϕyt−1−Xtβ_+ϕXt−1β_)2)\\begin{align} \\tag{5} logL\\left( \\underline{\\beta}, \\phi; \\underline{y} \\right ) &= const. + \\frac{1}{2}log(1-\\phi^2) \\\\ &-\\frac{n}{2}log\\left( (1-\\phi^2)(y_1-\\beta_0-\\beta_1)^2 + \\sum^n_{t=2}(y_t - \\phi y_{t-1}-\\beta_0(1-\\phi^2)-t\\beta_1 + \\phi(t-1)\\beta_1)^2 \\right) \\\\   &= const. + \\frac{1}{2}log(1-\\phi^2) \\\\ &-\\frac{n}{2}log\\left( (1-\\phi^2)(y_1-X_1\\underline{\\beta})^2 + \\sum^n_{t=2}(y_t - \\phi y_{t-1}-X_t\\underline{\\beta} + \\phi X_{t-1}\\underline{\\beta})^2 \\right)  \\end{align}","code":""},{"path":"https://andybeet.github.io/arfit/articles/Equations.html","id":"eq-6","dir":"Articles","previous_headings":"","what":"Eq 6","title":"Equations","text":"logL(β_,ϕ_,σ;y_)=−n2log(2π)−n2log(σ2)+12log|Vp−1|−12σ2(yp_−μp_)TVp−1(yp_−μp_)−12σ2∑t=p+1n(yt−c−ϕ1yt−1−...−ϕpyt−p)2\\begin{align} \\tag{6} logL\\left( \\underline{\\beta}, \\underline{\\phi},\\sigma; \\underline{y} \\right ) &= -\\frac{n}{2}log(2\\pi) -\\frac{n}{2}log(\\sigma^2) +\\frac{1}{2}log \\left|V_p^{-1} \\right| \\\\ &-\\frac{1 }{2 \\sigma^2} (\\underline{y_p}-\\underline{\\mu_p})^T V_p^{-1}(\\underline{y_p}-\\underline{\\mu_p}) \\\\  &- \\frac{1}{2\\sigma^2}\\sum^n_{t=p+1} (y_t - c - \\phi_1y_{t-1} - ... - \\phi_p y_{t-p})^2   \\end{align} |Vp−1|\\left|V_p^{-1} \\right| determinant inverted matrix VpV_p, σ2Vp\\sigma^2V_p = variance-covariance matrix order p, μp_=Xpβ_\\underline{\\mu_p} = X_p\\underline{\\beta}, XpX_p pthp_{th} row design matrix corresponding time t = p cc = function fitted terms Xtβ_X_t\\underline{\\beta}","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"likelihood-for-arp-errors","dir":"Articles","previous_headings":"","what":"Likelihood for AR(p) errors","title":"Background","text":"Hamilton (1994) logL(β_,ϕ_,σ;y_)=−n2log(2π)−n2log(σ2)+12log|Vp−1|−12σ2(yp_−μp_)TVp−1(yp_−μp_)−12σ2∑t=p+1n(yt−c−ϕ1yt−1−...−ϕpyt−p)2\\begin{align} logL\\left( \\underline{\\beta}, \\underline{\\phi},\\sigma; \\underline{y} \\right ) &= -\\frac{n}{2}log(2\\pi) -\\frac{n}{2}log(\\sigma^2) +\\frac{1}{2}log \\left|V_p^{-1} \\right| \\\\ &-\\frac{1 }{2 \\sigma^2} (\\underline{y_p}-\\underline{\\mu_p})^T V_p^{-1}(\\underline{y_p}-\\underline{\\mu_p}) \\\\  &- \\frac{1}{2\\sigma^2}\\sum^n_{t=p+1} (y_t - c - \\phi_1y_{t-1} - ... - \\phi_p y_{t-p})^2 \\\\  \\end{align} |Vp−1|\\left|V_p^{-1} \\right| determinant inverted matrix VpV_p, σ2Vp\\sigma^2V_p = variance-covariance matrix order p, μp_=Xpβ_\\underline{\\mu_p} = X_p\\underline{\\beta}, XpX_p pthp_{th} row design matrix corresponding time t = p cc = function fitted terms Xtβ_X_t\\underline{\\beta}","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"likelihood-for-ar1-errors","dir":"Articles","previous_headings":"","what":"Likelihood for AR(1) errors","title":"Background","text":"Setting p = 1, σ2V1=σ21−ϕ12\\sigma^2V_1 = \\frac{\\sigma^2}{1-\\phi_1^2} = variance process, y, |V1−1|=1−ϕ12\\left|V_1^{-1}\\right| = 1-\\phi_1^2 μ1=X1β_=β0+β1\\mu_1 = X_1\\underline{\\beta} = \\beta_0 + \\beta_1 c=Xtβ_−ϕ1Xt−1β_c = X_t\\underline{\\beta} - \\phi_1 X_{t-1}\\underline{\\beta} y1y_1 first observation log likelihood, logL(β_,ϕ1,σ;y_)=−n2log(2π)−n2log(σ2)+12log(1−ϕ12)−12σ2(y1−X1β_)2(1−ϕ12)−12σ2∑t=2n(yt−Xtβ_−ϕ1(yt−1−Xt−1β_))2\\begin{align}  logL\\left( \\underline{\\beta}, \\phi_1, \\sigma; \\underline{y} \\right ) &= -\\frac{n}{2}log(2\\pi) -\\frac{n}{2}log(\\sigma^2) +\\frac{1}{2}log(1-\\phi_1^2)  \\\\ &-\\frac{1 }{2 \\sigma^2} ({y_1}-X_1\\underline{\\beta})^2 (1-\\phi_1^2) \\\\ &- \\frac{1}{2\\sigma^2}\\sum^n_{t=2} (y_t - X_t\\underline{\\beta} - \\phi_1 (y_{t-1} -X_{t-1}\\underline{\\beta}))^2 \\\\  \\end{align} Differentiating logL(β_,ϕ1,σ;y_)logL\\left( \\underline{\\beta}, \\phi_1, \\sigma; \\underline{y} \\right ) respect σ\\sigma equating zero yields maximum likelihood estimator, σ̂2=1n[(y1−X1β_)2(1−ϕ12)+∑t=2n(yt−Xtβ_−ϕ1(yt−1−Xt−1β_))2]\\begin{align} \\hat{\\sigma}^2 = \\frac{1}{n}\\left[ (y_1-X_1\\underline{\\beta})^2(1-\\phi_1^2) + \\sum^n_{t=2} (y_t - X_t\\underline{\\beta} - \\phi_1 (y_{t-1} -X_{t-1}\\underline{\\beta}))^2 \\right]  \\end{align} Substituting σ̂2\\hat{\\sigma}^2 back log likelihood yields (Beach MacKinnon (1978a)) logL(β_,ϕ1;y_)=const.+12log(1−ϕ2)−n2log((y1−X1β_)2(1−ϕ12)+∑t=2n(yt−Xtβ_−ϕ1(yt−1−Xt−1β_))2)\\begin{align} logL\\left( \\underline{\\beta}, \\phi_1; \\underline{y} \\right ) &= const. +\\frac{1}{2}log(1-\\phi^2)  \\\\ &-\\frac{n}{2}log\\left( (y_1-X_1\\underline{\\beta})^2(1-\\phi_1^2) + \\sum^n_{t=2} (y_t - X_t\\underline{\\beta} - \\phi_1 (y_{t-1} -X_{t-1}\\underline{\\beta}))^2 \\right) \\\\ \\end{align} Two additional terms exist likelihood appear conditional likelihood used GLS procedures. term (y1−X1β_)2(1−ϕ12)(y_1-X_1\\underline{\\beta})^2(1-\\phi_1^2) ensures initial value effect estimates 12log(1−ϕ2)\\frac{1}{2}log(1-\\phi^2) constrains stationary condition hold.","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"maximization-of-the-likelihood","dir":"Articles","previous_headings":"Likelihood for AR(1) errors","what":"Maximization of the likelihood","title":"Background","text":"Maximization likelihood requires iterative numerical procedures. estimate β_\\underline{\\beta} maximizes log-likelihood conditional ϕ\\phi β̂_=(X*TX*)−1X*Ty*\\begin{align} \\underline{\\hat{\\beta}} = (X^{*T}X^*)^{-1}X^{*T}y^* \\end{align} X*=QXX^*=QX y*=Qyy^* = Qy QQ Prais Winsten transformation Q=[(1−ϕ12)1/20...−ϕ110......0−ϕ11]  \\begin{matrix} Q = \\end{matrix} \\begin{bmatrix} (1-\\phi_1^2)^{1/2} & 0 & ... \\\\ -\\phi_1 & 1 & 0 & ... \\\\ & & ... & 0 & -\\phi_1 & 1\\\\ \\end{bmatrix}  procedure searches ϕ1\\phi_1 required find maximum likelihood estimates β_\\underline\\beta, σ\\sigma, ϕ1\\phi_1","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"likelihood-for-ar2-errors","dir":"Articles","previous_headings":"","what":"Likelihood for AR(2) errors","title":"Background","text":"Following method AR(1) errors. Set p = 2, V2−1=[(1−ϕ22)−(ϕ1+ϕ1ϕ2)−(ϕ1+ϕ1ϕ2)(1−ϕ22)] \\begin{matrix} V_2^{-1} =  \\end{matrix} \\begin{bmatrix} (1-\\phi_2^2) & -(\\phi_1 + \\phi_1\\phi_2) \\\\ -(\\phi_1 + \\phi_1\\phi_2) & (1-\\phi_2^2)  \\\\ \\end{bmatrix} |V2−1|=(1+ϕ22)[(1−ϕ2)2−ϕ12]\\left|V_2^{-1}\\right| = (1+\\phi_2^2)\\left[(1-\\phi_2)^2 -\\phi_1^2 \\right] μ2_=(μ1,μ2)=(X1β_,X2β_)\\underline{\\mu_2} = (\\mu_1, \\mu_2) = (X_1\\underline{\\beta},X_2\\underline{\\beta}) vector means t = 1,2 y2_=(y1,y2)\\underline{y_2} = (y_1,y_2) corresponding vector observations [μ1μ2]=[1112][β0β1] \\begin{bmatrix}  \\mu_1 \\\\ \\mu_2 \\\\ \\end{bmatrix} = \\begin{bmatrix}  1 & 1 \\\\ 1 & 2 \\\\ \\end{bmatrix} \\begin{bmatrix}  \\beta_0 \\\\ \\beta_1 \\\\ \\end{bmatrix} c=Xtβ_−ϕ1Xt−1β_−ϕ2Xt−2β_c = X_t\\underline{\\beta} - \\phi_1 X_{t-1}\\underline{\\beta}- \\phi_2 X_{t-2}\\underline{\\beta} log likelihood, logL(β_,ϕ_,σ;y_)=−n2log(2π)−n2log(σ2)+12log((1+ϕ22)[(1−ϕ2)2−ϕ12])−12σ2(y2_−μ2_)TV2−1(y2_−μ2_)−12σ2∑t=3n(yt−Xtβ_−ϕ1(yt−1−Xt−1β_)−ϕ2(yt−2−Xt−2β_))2\\begin{align}  logL\\left( \\underline{\\beta}, \\underline{\\phi}, \\sigma; \\underline{y} \\right ) &= -\\frac{n}{2}log(2\\pi) -\\frac{n}{2}log(\\sigma^2) +\\frac{1}{2}log((1+\\phi_2^2)\\left[(1-\\phi_2)^2 -\\phi_1^2 \\right])  \\\\ &-\\frac{1 }{2 \\sigma^2} (\\underline{y_2}-\\underline{\\mu_2})^T V_2^{-1}(\\underline{y_2}-\\underline{\\mu_2}) \\\\ &- \\frac{1}{2\\sigma^2}\\sum^n_{t=3} (y_t - X_t\\underline{\\beta} - \\phi_1 (y_{t-1} -X_{t-1}\\underline{\\beta}) - \\phi_2 (y_{t-2} -X_{t-2}\\underline{\\beta}))^2 \\\\  \\end{align} Differentiating logL(β_,ϕ_,σ;y_)logL\\left( \\underline{\\beta}, \\underline{\\phi}, \\sigma; \\underline{y} \\right ) respect σ\\sigma equating zero yields maximum likelihood estimator, σ̂2=1n[(y2_−μ2_)TV2−1(y2_−μ2_)+∑t=3n(yt−Xtβ_−ϕ1(yt−1−Xt−1β_)−ϕ2(yt−2−Xt−2β_))2]\\begin{align} \\hat{\\sigma}^2 = \\frac{1}{n}\\left[ (\\underline{y_2}-\\underline{\\mu_2})^T V_2^{-1}(\\underline{y_2}-\\underline{\\mu_2}) + \\sum^n_{t=3} (y_t - X_t\\underline{\\beta} - \\phi_1 (y_{t-1} -X_{t-1}\\underline{\\beta}) - \\phi_2 (y_{t-2} -X_{t-2}\\underline{\\beta}))^2\\right]  \\end{align} Substituting σ̂2\\hat{\\sigma}^2 back log likelihood yields logL(β_,ϕ_;y_)=const.+12log((1+ϕ22)[(1−ϕ2)2−ϕ12])−n2log[(y2_−μ2_)TV2−1(y2_−μ2_)+∑t=3n(yt−Xtβ_−ϕ1(yt−1−Xt−1β_)−ϕ2(yt−2−Xt−2β_))2]\\begin{align} logL\\left( \\underline{\\beta}, \\underline{\\phi}; \\underline{y} \\right) &= const. +\\frac{1}{2}log\\left((1+\\phi_2^2)\\left[(1-\\phi_2)^2 -\\phi_1^2 \\right]\\right)  \\\\ &-\\frac{n}{2}log\\left[ (\\underline{y_2}-\\underline{\\mu_2})^T V_2^{-1}(\\underline{y_2}-\\underline{\\mu_2}) + \\sum^n_{t=3} (y_t - X_t\\underline{\\beta} - \\phi_1 (y_{t-1} -X_{t-1}\\underline{\\beta}) - \\phi_2 (y_{t-2} -X_{t-2}\\underline{\\beta}))^2\\right]\\\\ \\end{align} Simplifying , 12log((1+ϕ22)[(1−ϕ2)2−ϕ12])=log(1+ϕ2)+12log(1−ϕ1−ϕ2)+12log(1+ϕ1−ϕ2)\\begin{align} \\frac{1}{2}log\\left((1+\\phi_2^2)\\left[(1-\\phi_2)^2 -\\phi_1^2 \\right]\\right) = log(1+\\phi_2) + \\frac{1}{2}log(1-\\phi_1-\\phi_2)+\\frac{1}{2}log(1+\\phi_1-\\phi_2) \\end{align} (y2_−μ2_)TV2−1(y2_−μ2_)=[(y1−μ1)(y2−μ2)][(1−ϕ22)−(ϕ1+ϕ1ϕ2)−(ϕ1+ϕ1ϕ2)(1−ϕ22)][(y1−μ1)(y2−μ2)]\\begin{align} (\\underline{y_2}-\\underline{\\mu_2})^T V_2^{-1}(\\underline{y_2}-\\underline{\\mu_2}) = & \\begin{bmatrix} (y_1 - \\mu_1) & (y_2 -\\mu_2) \\\\ \\end{bmatrix}   \\begin{bmatrix} (1-\\phi_2^2) & -(\\phi_1 + \\phi_1\\phi_2) \\\\ -(\\phi_1 + \\phi_1\\phi_2) & (1-\\phi_2^2)  \\\\ \\end{bmatrix}  \\begin{bmatrix} (y_1 - \\mu_1) \\\\ (y_2 - \\mu_2) \\\\ \\end{bmatrix} \\end{align} =(y1−μ1)2(1−ϕ22)−2(y1−μ1)(y2−μ2)(ϕ1+ϕ1ϕ2)+(y2−μ2)2(1−ϕ22)=(y1−μ1)2(1−ϕ22)−2(y1−μ1)(y2−μ2)ϕ1(1+ϕ2)+(y2−μ2)2(1−ϕ22)=(y1−X1β_)2(1−ϕ22)−2(y1−X1β_)(y2−X2β_)ϕ1(1+ϕ2)+(y2−X2β_)2(1−ϕ22)\\begin{align} = & (y_1 - \\mu_1)^2(1-\\phi_2^2)-2(y_1 - \\mu_1)(y_2 - \\mu_2)(\\phi_1 + \\phi_1\\phi_2)+(y_2 - \\mu_2)^2(1-\\phi_2^2)\\\\ = & (y_1 - \\mu_1)^2(1-\\phi_2^2)-2(y_1 - \\mu_1)(y_2 - \\mu_2)\\phi_1(1 + \\phi_2)+(y_2 - \\mu_2)^2(1-\\phi_2^2) \\\\ = & (y_1 - X_1\\underline{\\beta})^2(1-\\phi_2^2)-2(y_1-X_1\\underline{\\beta})(y_2-X_2\\underline{\\beta})\\phi_1(1 + \\phi_2)+(y_2 -X_2\\underline{\\beta})^2(1-\\phi_2^2) \\end{align} likelihood now form found Beach MacKinnon (1978b) $$ \\begin{align} logL\\left( \\underline{\\beta}, \\underline{\\phi}; \\underline{y} \\right) &= const. +log(1+\\phi_2) + \\frac{1}{2}log(1-\\phi_1-\\phi_2)+\\frac{1}{2}log(1+\\phi_1-\\phi_2) \\\\ &-\\frac{n}{2}log\\left[ (y_1 - X_1\\underline{\\beta})^2(1-\\phi_2^2)-2(y_1-X_1\\underline{\\beta})(y_2-X_2\\underline{\\beta})\\phi_1(1 + \\phi_2)+(y_2 -X_2\\underline{\\beta})^2(1-\\phi_2^2) \\\\ + \\sum^n_{t=3} (y_t - X_t\\underline{\\beta} - \\phi_1 (y_{t-1} -X_{t-1}\\underline{\\beta}) - \\phi_2 (y_{t-2} -X_{t-2}\\underline{\\beta}))^2\\right]\\\\ \\end{align} $$","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"maximization-of-the-likelihood-1","dir":"Articles","previous_headings":"Likelihood for AR(2) errors","what":"Maximization of the likelihood","title":"Background","text":"case AR(1) model maximizing likelihood requires numerical methods. estimate β_\\underline{\\beta} maximizes log-likelihood conditional ϕ\\phi (Beach MacKinnon (1978b)) β̂_=(X*TX*)−1X*Ty*\\begin{align} \\underline{\\hat{\\beta}} = (X^{*T}X^*)^{-1}X^{*T}y^* \\end{align} X*=QXX^*=QX y*=Qyy^* = Qy QQ Prais Winsten transformation Q=[[(1−ϕ22)−ϕ12(1+ϕ2)/(1−ϕ2)]1/20...[ϕ12(1+ϕ2)/(1−ϕ2)]1/2(1−ϕ22)1/20...−ϕ2−ϕ110...0−ϕ2−ϕ110......0...0−ϕ2−ϕ11]  \\begin{matrix} Q = \\end{matrix} \\begin{bmatrix} \\left[(1-\\phi_2^2)-\\phi_1^2(1+\\phi_2)/(1-\\phi_2)\\right]^{1/2} & 0 & ... \\\\ \\left[\\phi_1^2(1+\\phi_2)/(1-\\phi_2)\\right]^{1/2} & (1-\\phi_2^2)^{1/2} & 0 & ... \\\\ -\\phi_2 & -\\phi_1 & 1 & 0 & ...\\\\ 0 & -\\phi_2 & -\\phi_1 & 1 & 0 & ...\\\\ ... \\\\ 0 & ... &0  & -\\phi_2 & -\\phi_1 & 1\\\\ \\end{bmatrix} procedure searches ϕ1\\phi_1 & ϕ2\\phi_2 required find maximum likelihood estimates β_\\underline\\beta, σ\\sigma, ϕ_\\underline{\\phi}","code":""},{"path":[]},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"ar1","dir":"Articles","previous_headings":"Likelihood from first principles","what":"AR(1)","title":"Background","text":"L(θ_;y_)=∏t=2np(Yt=yt│Yt−1=yt−1)×p(Y1=y1)L(\\underline{\\theta};\\underline{y})=\\prod_{t=2}^n p(Y_t = y_t │ Y_{t-1}=y_{t-1}) × p(Y_1=y_1) θ_=(β0,β1,ϕ,σ2)\\underline{\\theta} = (\\beta_0,\\beta_1,\\phi,\\sigma^2), p(Yt=yt│Yt−1=yt−1)p(Y_t = y_t │ Y_{t-1}=y_{t-1}) conditional distribution yty_t given yt−1y_{t-1} p(Y1=y1)p(Y_1=y_1) distribution first point. Exact likelihood AR(1) process. conditional likelihood multiplied marginal likelihood first point.","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"density-of-py_1y_1","dir":"Articles","previous_headings":"Likelihood from first principles","what":"Density of p(Y1=y1)p(Y_1=y_1)","title":"Background","text":"p(Y1=y1)p(Y_1=y_1) normally distributed mean = X1β_X_1\\underline{\\beta} equates β0+β1\\beta_0 + \\beta_1 variance = σ21−ϕ2\\frac{\\sigma^2}{1-\\phi^2} density: p(Y1=y1)=12πσ2/(1−ϕ2)exp(−12(y1−β0−β1σ/(1−ϕ2))2)p(Y_1=y_1) = \\frac{1}{\\sqrt{2\\pi}\\sqrt{\\sigma^2/(1-\\phi^2)}}exp \\left( -\\frac{1}{2}\\left( \\frac{ y_1 - \\beta_0-\\beta_1 }{\\sigma/\\sqrt(1-\\phi^2)}\\right)^2\\right)","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"density-of-py_t-y_t-y_t-1y_t-1","dir":"Articles","previous_headings":"Likelihood from first principles","what":"Density of p(Yt=yt│Yt−1=yt−1)p(Y_t = y_t │ Y_{t-1}=y_{t-1})","title":"Background","text":"conditional distribution p(Yt=yt│Yt−1=yt−1)p(Y_t = y_t │ Y_{t-1}=y_{t-1}) also normally distributed get round way: Recall yt=β0+β1t+uty_t = \\beta_0 + \\beta_1 t + u_t ϕyt−1=ϕβ0+ϕβ1(t−1)+ϕut−1\\phi y_{t-1} = \\phi \\beta_0 + \\phi \\beta_1 (t-1) + \\phi u_{t-1} yt−ϕyt−1=β0+β1t+ut−ϕβ0−ϕβ1(t−1)−ϕut−1y_t - \\phi y_{t-1} = \\beta_0 + \\beta_1 t + u_t - \\phi \\beta_0 - \\phi\\beta_1(t-1) -\\phi u_{t-1} yt=ϕyt−1+β0(1−ϕ)+β1(t−ϕt+ϕ)+ety_t   = \\phi y_{t-1} + \\beta_0(1-\\phi) + \\beta_1 (t - \\phi t+\\phi) + e_t Rearrange obtain yt−ϕyt−1−β0(1−ϕ)−β1(t−ϕt+ϕ)=ety_t   - \\phi y_{t-1} - \\beta_0(1-\\phi) - \\beta_1 (t - \\phi t+\\phi) = e_t normal distribution mean = 0 variance = σ2\\sigma^2 results p(Yt=yt│Yt−1=yt−1)=∏t=2n1σ2πexp(−12(yt−ϕyt−1−β0(1−ϕ)−β1(t−ϕt+ϕ)σ)2)p(Y_t = y_t │ Y_{t-1}=y_{t-1}) = \\prod_{t=2}^n \\frac{1}{\\sigma \\sqrt{2\\pi}}exp \\left( -\\frac{1}{2}\\left( \\frac{ y_t   - \\phi y_{t-1} - \\beta_0(1-\\phi) - \\beta_1 (t - \\phi t+\\phi)  }{\\sigma}\\right)^2\\right)","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"exact-likelihood-for-ar1","dir":"Articles","previous_headings":"Likelihood from first principles","what":"Exact likelihood for AR1","title":"Background","text":"likelihood therefore: L(θ_;y_)=∏t=2n1σ2πexp(−12(yt−ϕyt−1−β0(1−ϕ)−β1(t−ϕt+ϕ)σ)2)×12πσ2/(1−ϕ2)exp(−12(y1−β0−β1σ/(1−ϕ2))2)L(\\underline{\\theta};\\underline{y}) = \\prod_{t=2}^n \\frac{1}{\\sigma \\sqrt{2\\pi}}exp \\left( -\\frac{1}{2}\\left( \\frac{ y_t   - \\phi y_{t-1} - \\beta_0(1-\\phi) - \\beta_1 (t - \\phi t+\\phi)  }{\\sigma}\\right)^2\\right) \\times \\frac{1}{\\sqrt{2\\pi}\\sqrt{\\sigma^2/(1-\\phi^2)}}exp \\left( -\\frac{1}{2}\\left( \\frac{ y_1 - \\beta_0 -\\beta_1 }{\\sigma/\\sqrt(1-\\phi^2)}\\right)^2\\right) Taking logs simplifying results : logL(θ_;y_)=−nlogσ−n2log(2π)−12log(1−ϕ2)−12σ2((y1−β0−β1)2(1−ϕ2)+Σt=2n(yt−ϕyt−1−β0(1−ϕ)−β1(t−ϕt+ϕ))2) logL(\\underline{\\theta};\\underline{y}) = -nlog\\sigma -\\frac{n}{2}log(2\\pi)-\\frac{1}{2}log(1-\\phi^2) -\\frac{1}{2\\sigma^2} \\left( (y_1-\\beta_0 -\\beta_1)^2(1-\\phi^2) + \\Sigma_{t=2}^n (y_t-\\phi y_{t-1}-\\beta_0(1-\\phi)-\\beta_1(t-\\phi t + \\phi))^2 \\right) Note β0(1−ϕ)+β1(t−ϕt+ϕ)=β0−β0ϕ+β1t−β1ϕt+β1ϕ=β0+β1t−ϕ(β0+β1(t−1))=Xtβ_−ϕXt−1β_\\begin{align}  &\\beta_0(1-\\phi) + \\beta_1 (t - \\phi t+\\phi) \\\\ &= \\beta_0 -\\beta_0\\phi + \\beta_1t - \\beta_1\\phi t + \\beta_1\\phi \\\\ &= \\beta_0 + \\beta_1t - \\phi (\\beta_0 +  \\beta_1(t -1)) \\\\ &= X_t\\underline{\\beta} - \\phi X_{t-1}\\underline{\\beta}  \\end{align} Using notation Beach MacKinnon (1978a) can simplify log likelihood, logL(θ_;y_)=−nlogσ−n2log(2π)−12log(1−ϕ2)−12σ2((y1−X1β_)2(1−ϕ2)+Σt=2n(yt−Xtβ_−ϕ(yt−1−Xt−1β_)2)\\begin{align}  logL(\\underline{\\theta};\\underline{y}) &= -nlog\\sigma -\\frac{n}{2}log(2\\pi)-\\frac{1}{2}log(1-\\phi^2) \\\\ &-\\frac{1}{2\\sigma^2} \\left( (y_1-X_1\\underline{\\beta})^2(1-\\phi^2) + \\Sigma_{t=2}^n (y_t- X_t\\underline{\\beta} - \\phi( y_{t-1}- X_{t-1}\\underline{\\beta})^2 \\right)\\\\ \\end{align} substituting σ̂2\\hat\\sigma^2 get logL(β_,ϕ;y_)=const.+12log(1−ϕ2)−n2log((y1−X1β_)2(1−ϕ2)+∑t=2n(yt−Xtβ_−ϕ(yt−1−Xt−1β_))2)\\begin{align} logL\\left( \\underline{\\beta}, \\phi; \\underline{y} \\right ) &= const. +\\frac{1}{2}log(1-\\phi^2)  \\\\ &-\\frac{n}{2}log\\left( (y_1-X_1\\underline{\\beta})^2(1-\\phi^2) + \\sum^n_{t=2} (y_t - X_t\\underline{\\beta} - \\phi (y_{t-1} -X_{t-1}\\underline{\\beta}))^2 \\right) \\\\ \\end{align}","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"ar2","dir":"Articles","previous_headings":"Likelihood from first principles","what":"AR(2)","title":"Background","text":"L(θ_;y_)=∏t=2np(Yt=yt│Yt−1=yt−1,Yt−2=yt−2)×p(Y2=y2|Y1=y1)×p(Y1=y1)L(\\underline{\\theta};\\underline{y})=\\prod_{t=2}^n p(Y_t=y_t│Y_{t-1}=y_{t-1},Y_{t-2}=y_{t-2}) \\times p(Y_2=y_2 | Y_1=y_1) \\times p(Y_1=y_1) Following reasoning can obtain densities three components likelihood. exact likelihood product conditional likelihood, conditional distribution y2|y1y_2 | y_1 marginal distribution y1y_1.","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"density-of-py_1y_1-1","dir":"Articles","previous_headings":"Likelihood from first principles","what":"Density of p(Y1=y1)p(Y_1=y_1)","title":"Background","text":"p(Y1=y1)p(Y_1=y_1) normally distributed mean = X1β_X_1\\underline{\\beta} equates β0+β1\\beta_0 + \\beta_1 variance = σ21−ϕ12−ϕ22\\frac{\\sigma^2}{1-\\phi_1^2 - \\phi_2^2}","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"density-of-py_2y_2y_1y_1","dir":"Articles","previous_headings":"Likelihood from first principles","what":"Density of p(Y2=y2│Y1=y1)p(Y_2=y_2│Y_1=y_1)","title":"Background","text":"p(Y2=y2│Y1=y1)p(Y_2=y_2│Y_1=y_1) complicated. Need work ","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"density-of-py_t-y_t-y_t-1y_t-1y_t-2y_t-2","dir":"Articles","previous_headings":"Likelihood from first principles","what":"Density of p(Yt=yt│Yt−1=yt−1,Yt−2=yt−2)p(Y_t = y_t │ Y_{t-1}=y_{t-1},Y_{t-2}=y_{t-2})","title":"Background","text":"Recall yt=β0+β1t+uty_t = \\beta_0 + \\beta_1 t + u_t ϕ1yt−1=ϕ1β0+ϕ1β1(t−1)+ϕ1ut−1\\phi_1 y_{t-1} = \\phi_1 \\beta_0 + \\phi_1 \\beta_1 (t-1) + \\phi_1 u_{t-1} ϕ2yt−2=ϕ2β0+ϕ2β1(t−2)+ϕ2ut−2\\phi_2 y_{t-2} = \\phi_2 \\beta_0 + \\phi_2 \\beta_1 (t-2) + \\phi_2 u_{t-2} yt−ϕ1yt−1−ϕ2yt−2=β0+β1t+ut−ϕ1β0−ϕ1β1(t−1)−ϕ1ut−1−ϕ2β0−ϕ2β1(t−2)−ϕ2ut−2y_t - \\phi_1 y_{t-1} - \\phi_2 y_{t-2} = \\beta_0 + \\beta_1 t + u_t - \\phi_1 \\beta_0 - \\phi_1\\beta_1(t-1) -\\phi_1 u_{t-1} - \\phi_2 \\beta_0 - \\phi_2\\beta_1(t-2) -\\phi_2 u_{t-2} simplifies yt−ϕ1yt−1−ϕ2yt−2−β0(1−ϕ1−ϕ2)−β1(t−ϕ1(t−1)−ϕ2(t−2))=ety_t - \\phi_1 y_{t-1} - \\phi_2 y_{t-2} - \\beta_0 (1-\\phi_1-\\phi_2) - \\beta_1 (t - \\phi_1(t-1)- \\phi_2(t-2))  = e_t results p(Yt=yt│Yt−1=yt−1,Yt−2=yt−2)=∏t=3n1σ2πexp(−12(yt−ϕ1yt−1−ϕ2yt−2−β0(1−ϕ1−ϕ2)−β1(t−ϕ1(t−1)−ϕ2(t−2))σ)2)p(Y_t = y_t │ Y_{t-1}=y_{t-1},Y_{t-2}=y_{t-2}) = \\prod_{t=3}^n \\frac{1}{\\sigma \\sqrt{2\\pi}}exp \\left( -\\frac{1}{2}\\left( \\frac{ y_t - \\phi_1 y_{t-1} - \\phi_2 y_{t-2} - \\beta_0 (1-\\phi_1-\\phi_2) - \\beta_1 (t - \\phi_1(t-1)- \\phi_2(t-2))  }{\\sigma}\\right)^2\\right)","code":""},{"path":"https://andybeet.github.io/arfit/articles/background_work.html","id":"exact-likelihood-for-ar2","dir":"Articles","previous_headings":"","what":"Exact likelihood for AR2","title":"Background","text":"likelihood therefore:","code":""},{"path":[]},{"path":"https://andybeet.github.io/arfit/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Andy Beet. Author, maintainer.","code":""},{"path":"https://andybeet.github.io/arfit/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Beet (2024). arfit: Fits full AR1 model. R package version 0.0.0.9000.","code":"@Manual{,   title = {arfit: Fits full AR1 model},   author = {Andy Beet},   year = {2024},   note = {R package version 0.0.0.9000}, }"},{"path":[]},{"path":[]},{"path":"https://andybeet.github.io/arfit/index.html","id":"legal-disclaimer","dir":"","previous_headings":"Contact","what":"Legal disclaimer","title":"Fits full AR1 model","text":"repository scientific product official communication National Oceanic Atmospheric Administration, United States Department Commerce. NOAA GitHub project code provided ‘’ basis user assumes responsibility use. claims Department Commerce Department Commerce bureaus stemming use GitHub project governed applicable Federal law. reference specific commercial products, processes, services service mark, trademark, manufacturer, otherwise, constitute imply endorsement, recommendation favoring Department Commerce. Department Commerce seal logo, seal logo DOC bureau, shall used manner imply endorsement commercial product activity DOC United States Government.","code":""},{"path":"https://andybeet.github.io/arfit/reference/arfit-package.html","id":null,"dir":"Reference","previous_headings":"","what":"arfit: Test for a trend in presence of autocorrelation — arfit-package","title":"arfit: Test for a trend in presence of autocorrelation — arfit-package","text":"Tools test trend presence autocorrelation. tools reproduce results publication","code":""},{"path":"https://andybeet.github.io/arfit/reference/arfit-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"arfit: Test for a trend in presence of autocorrelation — arfit-package","text":"Simulates data Evaluates likelihood Fits likelihood Estimates MLE model Example provided Tools simulation study","code":""},{"path":"https://andybeet.github.io/arfit/reference/arfit-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"arfit: Test for a trend in presence of autocorrelation — arfit-package","text":"learn using arfit, start vignette: browseVignettes(package=\"arfit\") click index ","code":""},{"path":[]},{"path":"https://andybeet.github.io/arfit/reference/arfit-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"arfit: Test for a trend in presence of autocorrelation — arfit-package","text":"Maintainer: Andy Beet andrew.beet@noaa.gov (ORCID)","code":""},{"path":"https://andybeet.github.io/arfit/reference/check_data_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks data set for misspecification — check_data_validation","title":"Checks data set for misspecification — check_data_validation","text":"Check column names, missing data, consecutive equally spaced time units","code":""},{"path":"https://andybeet.github.io/arfit/reference/check_data_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks data set for misspecification — check_data_validation","text":"","code":"check_data_validation(dataSet)"},{"path":"https://andybeet.github.io/arfit/reference/est_beta_given_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate beta conditional on known AR1 parameter — est_beta_given_rho","title":"Estimate beta conditional on known AR1 parameter — est_beta_given_rho","text":"Uses Prais Winsten transformation utilizes first observation","code":""},{"path":"https://andybeet.github.io/arfit/reference/est_beta_given_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate beta conditional on known AR1 parameter — est_beta_given_rho","text":"","code":"est_beta_given_rho(xt, yt, rho)"},{"path":"https://andybeet.github.io/arfit/reference/est_beta_given_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate beta conditional on known AR1 parameter — est_beta_given_rho","text":"xt Numeric vector. Time series time points (1, ..., n) yt Numeric vector. Time series observations (length = n) rho Numeric scalar. AR1 parameter","code":""},{"path":"https://andybeet.github.io/arfit/reference/example_cedar_rapids.html","id":null,"dir":"Reference","previous_headings":"","what":"Run test on example data set — example_cedar_rapids","title":"Run test on example data set — example_cedar_rapids","text":"Use data USGS 05464500 Cedar River Cedar Rapids, IA","code":""},{"path":"https://andybeet.github.io/arfit/reference/example_cedar_rapids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run test on example data set — example_cedar_rapids","text":"","code":"example_cedar_rapids(dataSet = arfit::cedar_rapids, nBootSims = 999)"},{"path":"https://andybeet.github.io/arfit/reference/example_cedar_rapids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run test on example data set — example_cedar_rapids","text":"dataSet Data frame. Two columns (year, riverflow) nBootSims Numeric scalar. Number bootstrap samples perform","code":""},{"path":"https://andybeet.github.io/arfit/reference/fit_ar1_opt.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit linear model with trend using optimization routine — fit_ar1_opt","title":"Fit linear model with trend using optimization routine — fit_ar1_opt","text":"Fit linear model trend using optimization routine","code":""},{"path":"https://andybeet.github.io/arfit/reference/fit_ar1_opt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit linear model with trend using optimization routine — fit_ar1_opt","text":"","code":"fit_ar1_opt(data, rho, hypothesis)"},{"path":"https://andybeet.github.io/arfit/reference/fit_real_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Run test on real data set — fit_real_data","title":"Run test on real data set — fit_real_data","text":"Supply data","code":""},{"path":"https://andybeet.github.io/arfit/reference/fit_real_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run test on real data set — fit_real_data","text":"","code":"fit_real_data(dataSet, nBootSims = 499, printFig = F)"},{"path":"https://andybeet.github.io/arfit/reference/fit_real_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run test on real data set — fit_real_data","text":"dataSet Data frame. Two columns (x, y) nBootSims Numeric scalar. Number bootstrap samples perform printFig Boolean. Print data fit figure window (Default = F)","code":""},{"path":"https://andybeet.github.io/arfit/reference/likelihood_ar1.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the likelihood of linear model with errors from an AR order 1 process — likelihood_ar1","title":"Evaluate the likelihood of linear model with errors from an AR order 1 process — likelihood_ar1","text":"Evaluate likelihood linear model errors AR order 1 process","code":""},{"path":"https://andybeet.github.io/arfit/reference/likelihood_ar1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the likelihood of linear model with errors from an AR order 1 process — likelihood_ar1","text":"","code":"likelihood_ar1(rho, dataf, hypothesis = \"null\")"},{"path":"https://andybeet.github.io/arfit/reference/likelihood_ar1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the likelihood of linear model with errors from an AR order 1 process — likelihood_ar1","text":"rho Numeric scalar. Autoregressive parameter dataf Data frame. (nx2). Defining xt yt values hypothesis Character string. \"null\" \"alt\" determines whether evaluate null alternative hypothesis. \"null\" fixes linear component, beta = 0.","code":""},{"path":"https://andybeet.github.io/arfit/reference/likelihood_ar1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the likelihood of linear model with errors from an AR order 1 process — likelihood_ar1","text":"likelihod value","code":""},{"path":"https://andybeet.github.io/arfit/reference/sim_study_opt_ar1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation study using optimization routine, multiple cores — sim_study_opt_ar1","title":"Simulation study using optimization routine, multiple cores — sim_study_opt_ar1","text":"Performs simulation study assess performance test. Utilizes multiple cores spread bootstrap samples multiple cores","code":""},{"path":"https://andybeet.github.io/arfit/reference/sim_study_opt_ar1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation study using optimization routine, multiple cores — sim_study_opt_ar1","text":"","code":"sim_study_opt_ar1(   outDir = here::here(\"out.txt\"),   betaVec = c(0, 0.12, 0.25, 0.5),   rhoVec = c(0, 0.25, 0.5, 0.75, 0.95),   sigmaVec = c(0.25, 0.5, 0.75),   nTVec = c(10, 25, 50),   nSims = 200,   nBootSims = 500,   setSeed = NULL,   nCores = NULL,   missing = F )"},{"path":"https://andybeet.github.io/arfit/reference/sim_study_opt_ar1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation study using optimization routine, multiple cores — sim_study_opt_ar1","text":"outDir Character string. Path output file betaVec Numeric vector. Values beta_1 (slope/trend parameter) rhoVec Numeric vector. Values autoregressive parameter sigmaVec Numeric vector. Values standard deviation noise nSims Numeric scalar. Number time series simulate nBootSims Numeric scalar. Number bootstrap data sets setSeed Numeric scalar. Value seed simulations. (Default = NULL, random number 1-e7 selected) nCores Numeric scalar. Specify number cores utilize (Default = NULL, utilizes n-1 cores) missing Boolean. Whether simulate missing data (Default = F). T single missing value added random response nVec Numeric vector. Values length time series simulate","code":""},{"path":"https://andybeet.github.io/arfit/reference/sim_study_opt_ar1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation study using optimization routine, multiple cores — sim_study_opt_ar1","text":"convenience intercept, beta_0 set zero","code":""},{"path":"https://andybeet.github.io/arfit/reference/sim_study_opt_ar1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation study using optimization routine, multiple cores — sim_study_opt_ar1","text":"","code":"if (FALSE) { # \\dontrun{ } # }"},{"path":"https://andybeet.github.io/arfit/reference/simulate_ar1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data from an linear process with AR1 error — simulate_ar1","title":"Simulate data from an linear process with AR1 error — simulate_ar1","text":"model=   y_t = + bt + z_t z_t = rho z_t-1 + e_t   (e_t ~ N(0,sigma^2)) Uses unconditional mean variance simulate first data point","code":""},{"path":"https://andybeet.github.io/arfit/reference/simulate_ar1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data from an linear process with AR1 error — simulate_ar1","text":"","code":"simulate_ar1(alpha, beta = 0, sigma, rho, n, missingValues = NULL)"},{"path":"https://andybeet.github.io/arfit/reference/simulate_ar1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data from an linear process with AR1 error — simulate_ar1","text":"alpha Numeric scalar. Intercept beta Numeric scalar. Slope sigma Numeric scalar. Standard deviation error term rho Numeric scalar. Auto regressive parameter n Numeric scalar. Length time series missingValues Numeric vector. Indices y values missing data","code":""},{"path":"https://andybeet.github.io/arfit/reference/simulation_study_opt_ar1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation study using optimization routine — simulation_study_opt_ar1","title":"Simulation study using optimization routine — simulation_study_opt_ar1","text":"Uses single Core. Performs simulation study assess performance test.","code":""},{"path":"https://andybeet.github.io/arfit/reference/simulation_study_opt_ar1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation study using optimization routine — simulation_study_opt_ar1","text":"","code":"simulation_study_opt_ar1(   outDir = here::here(\"out.txt\"),   betaVec = c(0.12, 0.25, 0.5),   rhoVec = c(0, 0.25, 0.5, 0.75, 0.95),   sigmaVec = c(0.25, 0.5, 0.75),   nTVec = c(10),   nSims = 200,   nBootSims = 500 )"},{"path":"https://andybeet.github.io/arfit/reference/simulation_study_opt_ar1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation study using optimization routine — simulation_study_opt_ar1","text":"outDir Character string. Path output file betaVec Numeric vector. Values beta_1 (slope/trend parameter) rhoVec Numeric vector. Values autoregressive parameter sigmaVec Numeric vector. Values standard deviation noise nSims Numeric scalar. Number time series simulate nBootSims Numeric scalar. Number bootstrap data sets nVec Numeric vector. Values length time series simulate","code":""},{"path":"https://andybeet.github.io/arfit/reference/simulation_study_opt_ar1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation study using optimization routine — simulation_study_opt_ar1","text":"convenience intercept, beta_0 set zero","code":""},{"path":"https://andybeet.github.io/arfit/reference/simulation_study_opt_ar1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation study using optimization routine — simulation_study_opt_ar1","text":"","code":"if (FALSE) { # \\dontrun{ simulation_study_opt(here::here(\"output.txt\"),betaVec = 0.5,rhovec =0.5, sigmaVec = 0.25, nTVec = 10, nSims = 200, nBootSims = 500) } # }"}]
